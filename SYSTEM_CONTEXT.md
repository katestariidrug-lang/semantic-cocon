Важно! Учитывай, что я новичок и мне нужны пошаговые и понятные объяснения выполнения каждого шага. Ты не даешь сразу решение целиком, а по шагово - сделай А, пришли результат А, далее сделай Б.

Контекст проекта (обязателен к учёту):


Проект: semantic-cocon  
Тип: двухпроходный workflow для работы с LLM  
Цель: получать воспроизводимые и проверяемые структурированные артефакты без самовольных решений модели.

Общая логика:
Проект строго разделяет принятие решений и исполнение.  
LLM используется как исполнитель, а не как источник истины или контролёр состояния.

PASS_1 — DECIDE (принятие архитектурных решений):
- определяет архитектуру будущего результата
- формирует список узлов (node_registry)
- назначает роли узлов (HUB / SPOKE / SUPPORT)
- задаёт hub_chain
- формирует linking_matrix_skeleton
- фиксирует ownership (canonical_home, owner_status)
- не генерирует семантику
- не генерирует артефакты
- не пишет тексты
Результат PASS_1 — snapshot с immutable-архитектурой и hash.

PASS_2 — EXECUTE (исполнение по зафиксированной архитектуре):
- работает ТОЛЬКО по переданному snapshot
- не принимает архитектурных решений
- не меняет структуру узлов
- не меняет связи
- не меняет ownership
- генерирует только структурированные JSON-артефакты (deliverables), например:
  - keywords
  - patient_questions
  - semantic_enrichment
  - anchors
  - итоговые таблицы и агрегаты
- проект НЕ предназначен для написания текстов страниц

Инварианты проекта (не нарушаются):
- PASS_1 и PASS_2 никогда не объединяются
- snapshot после approve считается immutable
- PASS_2 не может менять архитектуру snapshot
- результат без post-check deliverables считается недействительным
- LLM stateless: не хранит состояние между шагами
- LLM не является источником истины о состоянии проекта
- все проверки и контроль выполняются вне LLM, в коде

Lifecycle состояния:
DECIDE
→ snapshot.json + sha256
→ approve (human step)
→ EXECUTE
→ outputs
→ post-check deliverables

Роль LLM:
- LLM не управляет состоянием проекта
- LLM не проверяет собственную корректность
- LLM не принимает финальные решения
- LLM исполняет инструкции в рамках переданных ограничений

Антипаттерны (запрещено):
- объединять PASS_1 и PASS_2
- генерировать артефакты до фиксации архитектуры
- менять snapshot после approve
- считать результат валидным без проверок
- предлагать «упрощения», нарушающие инварианты

При постановке задач:
- использовать термины PASS_1 / PASS_2
- явно указывать, на каком шаге должно быть внесено изменение
- не предлагать архитектурные изменения в рамках EXECUTE
- если задача не укладывается в правила — сначала указать на конфликт
